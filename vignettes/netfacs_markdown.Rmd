---
title: "Netfacs Overview"
author: "Alex Mielke"
date: '2019-12-12'
output:
  html_document: default
  pdf_document: default
geometry: "left=0.5cm,right=0.5cm,top=2cm,bottom=2cm"
---
<style type="text/css">

body{ /* Normal  */
      font-size: 12px;
  }
td {  /* Table  */
  font-size: 10px;
}
code.r{ /* Code block */
    font-size: 8px;
}
</style>


```{r, echo = F}
options(warn=-1)
```

# Introduction

This is a tutorial/overview over which functions are currently available in the NetFACS package and which questions we can potentially already answer. I will demonstrate the whole process of creating a NETFACS object, and explain the existing analytical and plotting tools. 

Currently, all functions are concerned with co-occurrence, so which elements/AUs happen simultaneously. Time-series analyses should follow soon. While I will use mainly FACS examples throughout (meaning 'elements' in the functions are action units), the functions can be applied to any co-occurrence data, so other questions regarding communication are also possible, and even social networks can be analysed. 

Probabilities are established using the apriori function in the 'arules' package, and later on there will be functions that make specific use of this package for plotting and analyses. Throughout, all measures represent probabilities of occurrance and co-occurrance, changes in probabilities etc. Two types of probability will be essential here: one is the absolute probability of a combination occurring (just labeled 'probability' throughout), called 'support' in arules; the other is the conditional probability of one event happening when another is present (either element occurring when other occurs, or element being tied to certain conditions), which is called 'confidence' in arules. Probabilities are used as they are intuitive for most people, in contrast to many more opaque association indices that are often used in social network analysis. It also means that we can tie in other analytical tools that are very directly based on probabilities, such as Bayesian models and Markov Chains, and the interpretation does not change.

Let's start by creating the package and loading the library:

```{r, echo = T}
suppressMessages(library(netfacs))
```

```{r, echo = F}
suppressMessages(library(knitr))
```

### Datasets

Currently, there are two practice datasets in the package: one is the Cohn-Kanade Database for posed FACS data (all basic AUs, 6 emotions), where co-occurrence is defined as AUs happening in the same facial expression, and one is the Communist Manifesto in French, German, and English, where co-occurrence is defined as letters happening in the same word (I needed something that was public access and had a lot of cases). These can be accessed the following way:

```{r}
data('letternet') # this is the Manifesto # 
data('emotions_set') # this is the CK Database #
```

Here is what the emotions_set data look like:

```{r, echo = F, cache=T}
au.data = emotions_set[[1]] # matrix with each AU as a column, and each event as a row
kable(head(au.data), row.names = F)
au.info = emotions_set[[2]] # additional information on subjects, emotions etc
kable(head(au.info), row.names = F)
```

I will do all examples with the CK emotion database.

# The NETFACS function

The basis for the whole package so far is the 'netfacs' function. The function creates a list that has for all possible combination of elements information on their observed probability of occurrence in the chosen dataset. It also tests whether this observed probability is significantly different from an expected or null distribution. The user defines whether this null distribution is the expected random distribution of elements (e.g., do AU1 and AU2 occur together more than expected by chance) based on permutations of the raw data, or whether we are comparing two conditions (e.g., do AU1 and AU2 occur together more in sad than in angry faces) with one condition providing the null condition. In the latter case, bootstraps of the null condition are used to establish the null distribution. Bootstraps can be done by randomly selecting events, or by randomly selecting on a higher-level variable, e.g. subject, by including that variable in the 'random.level' parameter of the function call. One can include 'control variables' into the bootstrap: for example, if individual sex is included, then the bootstrap will select the null condition on the same ratio as the test condition, so if 1/3 participant in the test condition are males, then 1/3 of cases in each random selection will also be male. This prevents biases due to sampling differences between test and null condition.

Here, I will give an example where we compare the facial expression of anger against all other facial expression. Every individual provided one case and there is no information about gender etc so we do not use any controls:

### Comparison of conditions
```{r angry, cache=T}
# here, we test whether any action units and combinations appear more frequently than expected under one condition than under another. 
angry.face = netfacs(data = au.data, # this is the dataset
                                  condition = au.info$emotion, # info about which condition each cases belongs to
                                  test.condition = 'anger', # condition we are interested in
                                  null.condition = NULL,  # null condition (here, against all other emotions)
                                  duration = NULL, # we could add duration information
                                  ran.trials = 100, # number of randomizations. 1000 is good but slow 
                                  control = NULL, # control for certain variables, e.g.sex, gender, ethnicity etc.
                                  random.level = NULL, # Works like a random effect.
                                  combination.size = NULL # limit the analysis to make things faster
                                  )

```

Now we have the angry.face object that contains all the information we need to make networks and claims about which action units make up a facial expression.

```{r, echo = F}
kable(head(angry.face$result[angry.face$result$count>0,], 10), row.names = F, align = 'c')
```

As we can see in the last table already, there is a lot of information in this object: 
 - combination: the name of the combination 
 - combination.size: how many elements make up the combination
 - count: how often it occurs in the test condition
 - observed.probability: Probability that the combination occurs in a frame of that condition
 - expected.probability: Expected probability of the combination if the dataset was drawn from the null condition
 - z: test statistic, how many standard deviations does the observed probability differ from the mean of all randomisations
 - pvalue: how many random probabilities were more extreme than the observed probability
 - specificity: probability that the condition is 'anger' when the combination is observed. e.g, 0.8 means that 80% of all occurrances of the action unit are in 'anger'
 - probability.increase: how many times more likely is the combination in this condition than the null condition? (Effect size)
 
 As this table is pretty massive, we can extract results more easily while already cleaning the table a bit using the 'extract.netfacs' function:
 
```{r, cache=T}
anger.aus = extract.netfacs(netfacs.data = angry.face, 
                level = 1, # only looking at combinations with 1 element (here, action units)
                min.count = 1, # minimum number of times that the combination should occurr
                min.prob = 0, # minimum observed probability of the combination
                min.specificity = 0, # minimum specificity of the combination
                significance = 0.01) # significance level we are interested in
kable(anger.aus[order(-1*anger.aus$probability.increase),], align = 'c', row.names = F)
```

The results show that in angry faces, the action units 4, 7, 14, 17, 18, 23, and 24 are significantly more common than would be expected given the information we have from the other emotions. AU23, for example, occurrs 36 times, which is 80% of all 'angry' faces. Expected would be 2.5%, so we have an increase in probability of 32 times. When we see AU 23, we can be 83.7% sure that this is an angry face (specificity). 

We can also plot this. Almost all plots that are included in the package at this point are ggplot based, so the user can subsequently change most parameters to their own liking.


```{r element.plot, fig.width=4, fig.height=4, fig.align='center', message=F}
element.plot(netfacs.data = angry.face)
```


This is as far as most FACS analyses go so far: which action units are more active under certain condition. However, what we can do now is look at higher-order combinations of action units. Let's look at combinations of 3 action units. As there are many combinations that only occur once or twice, and these are probably not very important, let's set the minimum count that we consider meaningful to 5.

```{r, echo = F}
anger.aus3 = extract.netfacs(netfacs.data = angry.face, 
                level = 3, # only looking at combinations with 1 element (here, action units)
                min.count = 5, # minimum number of times that the combination should occurr
                min.prob = 0, # minimum observed probability of the combination
                min.specificity = 0, # minimum specificity of the combination
                significance = 0.01) # significance level we are interested in
kable(anger.aus3[order(-1*anger.aus3$probability.increase),], align = 'c', row.names = F)
```

Here, we see that for example combination AU4_17_24 appears 28 times, with is 44 times more than we would have expected. Many of the combinations only occurr in the angry condition. That many of these higher-order combinations contain very similar combinations (e.g. AU4_17_23 and AU4_17_24) can mean two things: either, they are significant because all these elements declare anger and they are combine randomly; or they are all part of one standard higher-order combination (e.g. AU4_17_23_24) that occurs over and over again. By looking at the different levels, we can potentially resolve this question.


## Element specificity

One question that is of relevance in this context is which element/action unit actually contributes to our decoding of the message that the other one is trying to send. For example, Au1 and AU2 will both appear on their own, but also as AU1_2, AU1_2_5, AU1_2_5_26 etc. The question is whether both of the action units actually add information about the condition: If I remove AU1 from AU1_2_5_26, does the resulting combination still convey the same message? We do this through the specificity (i.e., strength association of the element with the condition in question): the function 'element.specificity' goes through all combinations that contain an element and calculates the mean specificity with and without the element. The result  tells us which action units actually add the information 'angry!' and which ones potentially just appear as part of combinations:

```{r}
kable(element.specificity(netfacs.data = angry.face)[1], align = 'c', row.names = F, digits = 2)
```

Here, we see that even though AU5 is pretty rare, as it only occurred 6 times, and is in itself not very specific to the context of anger (only 5% of all events containing AU5 occur in anger), adding AU5 to other combinations makes them 'angry': the specificity increases by 30%. Combinations that would usually be relatively neutral (for example, wrinkling your forehead) look really angry if you add some eye flashing. Thus, AU5 on itself is not a sign of anger, but when added to other combinations it might have a different function. A smile (AU12) actually decreases the likelihood that a combination is 'angry'.

To understand the importance of any element in our communication system, we should probably look for the ones that combine both aspects: they should be common in the context (i.e., high probability), but they should also be limited to that context (i.e., high specificity).


## Combination sizes

One question that might be of interest when we talk about complexity could be whether the number of elements is larger than expected in a context: for example, it might be that happy faces usually use fewer elements than angry faces because there is less information necessary to transmit the message. The 'netfacs' function also pops out the observed probabilities that events consist of 1, 2, 3 ... elements, and this is tested against the null distribution.


```{r, echo = F}
kable(angry.face$event.size.information$total.event.sizes, align = 'c', row.names = F, digits = 2)
event.size.plot(netfacs.data = angry.face)
```

What the table and plot show us is that angry faces are actually quite complex, compared to the other emotions: events containing 0-3 action units are basically absent; combinations of 4, 6 and 8 action units are significantly more common than expected. Combinations of 5 action units are common (making up a third of cases), but this is within the range of combination sizes for all emotions.

If we do the same for happy faces, we see a very different pattern
```{r happy, echo=F}
happy.face = netfacs(data = au.data, condition = au.info$emotion, test.condition = 'happy', ran.trials = 100)
```

```{r, echo = F}
kable(happy.face$event.size.information$total.event.sizes, align = 'c', row.names = F, digits = 2)
```

In happy faces, combinations of 3 elements are by far the most likely, while all other combination sizes occur less than expected.


\newpage
# Networks

Now that we have our information about the probabilities of different elements and conditions extracted, we can start looking at different networks that potentially contain information about our action units that we rarely consider. There are different networks here that are of interest: first, we can make a bipartite network that shows us how different conditions are linked and which action units are specific to certain context. To a have high information value, we would expect an action unit to have high specificity in one context and that context only. Second, we can use networks to visualise the connections between action units. Third, we can use network metrics to identify central action units in a condition, and understand the network as a whole better.

## Overlap networks

Let's start with the overlap network: we can visualise which conditions (in our case, emotions), share action units. To make the process easier, there is a 'multiple.netfacs' function that runs the netfacs function for all levels of a condition against all others.

```{r}
multi.facs = multiple.netfacs(data = au.data, condition = au.info$emotion, ran.trials = 100, combination.size = 2) # I restrict the combination size because we only care about combinations of 2 action units when we make the networks
```

Now we can make a network where each condition is a node, and they are connected through the action units. We only consider action units that occur at least 5 times in the condition. Let's also remove action unit 25 because it's a bit pointless.

```{r overlap, fig.height=4, fig.width=4, fig.align='center', message=F}
p = overlap.network(netfacs.list = multi.facs, min.prob = 0, min.count = 5, significance = 0.01, ignore.element = '25')
p
```

Network! Now, we have an easy way to understand our FACS data: Happy and Contempt share AU12, but in happy it is combined with AU6, while in Contempt it is combined with AU14. AU17 is used in a variety of emotions (anger, disgust, sadness), while AU20 is pretty exclusive to Fear (92% specificity).


## Network visualisation

To do all the following calculations, we extract the netfacs object and turn it into a network with specific properties. Here goes:

```{r angry.net}
 angry.net = netfacs.network(netfacs.data = angry.face,
                             package = 'igraph', # can also be 'sna'
                             link = 'unweighted', # the network contains 1 when AUs are significantly connected
                             significance = 0.01, 
                             min.count = 5, # again remove rare connections as they might be random variation
                             min.prob = 0, 
                             min.specificity = 0, 
                             ignore.element = '25' # I really don't like AU25 
                             )
```

Now we have our angry.net, which is an 'igraph' object. 'igraph' is the most commonly used package for social network analysis, so now we can use all the functions that have been developed for social networks.

Let's plot our network for angry faces.

```{r angry.plot, fig.width=4, fig.height=4, fig.align='center', message=F}
p = network.plot(netfacs.graph = angry.net, title = 'angry network', clusters = F)
p
```

This looks like a pretty tight cluster of some action units that tend to occur together. AU5 and AU6 are not significantly more common in this context than expected, but occur in combination with other AUs more than expected (that's why they are smaller). This is again relatively different from the other networks: we can apply the netfacs.network function across our conditions to get a visual representation of how networks differ:

```{r multi.net}
 multi.net = multiple.netfacs.network(netfacs.list = multi.facs,
                             package = 'igraph', # can also be 'sna'
                             link = 'unweighted', # means that the network contains 1 when AUs are significantly connected, and 0 if they are not
                             significance = 0.01, 
                             min.count = 5, # again remove rare connections as they might be random variation
                             min.prob = 0, 
                             min.specificity = 0, 
                             ignore.element = '25' # I really don't like AU25 
                             )
```

```{r multi.plot, fig.width=10, fig.height=6, fig.align='center', message=F}
p = multiple.network.plot(netfacs.graphs = multi.net)
p
```

Here, we can see that the network for anger actually looks pretty complex compared to the other networks: in Contempt, only the combination of AU12 and 14 occurs more often than expected. Also, not all dyads in Anger are connected, indicating that they do not always all occur together. This is very different in Surprise, for example, where all significant AUs are also significantly more likely to co-occur.

One interesting aspect of network analysis is that we might be able to move away from our posed facial expressions and detect unknown underlying patterns. For example, if we would not know which emotion was posed, would we be able to analytically detect the basic emotions because specific action units cluster with each other? Let's create a network based on all data.

```{r all.face, cache=F}
all.face = netfacs(data = au.data, condition = NULL, ran.trials = 100, combination.size = 2)
all.net = netfacs.network(netfacs.data = all.face, min.count = 3, ignore.element = '25')
```


In this network, dyadic connections between action units mean that they occur more often together than would be expected given their own likelihood and the number of elements per event. When plotting this network, we can say 'clusters = T'. In that case, 'igraph' has a community detection algorithm (groups of AUs that form clusters). 
```{r all.plot, fig.width=4, fig.height=4, fig.align='center', message=F}
p = network.plot(netfacs.graph = all.net, title = 'all network with clusters', clusters = T)
p
```

Modularity is high (0.43; above 0.3 is high). This means that there are clear clusters (AUs that are connected with each other, but not others). First, some AUs just drop out because they do not connect with any of the others (AU22). Then we have a 'happy' network (AU6 and AU12), a 'surprise' network (AU1,2,5,26,27). Fear is specifically associated with AU10,16,20. Anger, Sadness, Disgust, and Contempt all overlap in their use of AU4 and 17, which are also the most central AUs of the remaining cluster. Given the small size of this dataset, even without previous knowledge of where the emotions fall, we could assume that there are at least 4 distinct clusters in the data.

## Network parameters

While making graphs is nice, having our FACS data as networks also allows us to calculate the centrality and importance of specific elements in the network. Again, an action unit that conclusively describes a specific emotion should be highly central in that network, but not at all central in any other. There are a number of different centrality measures, and one can extract them all at once.

```{r}
kable(network.summary(angry.net), align = 'c', row.names = F, digits = 3)
```

The different network measures capture different aspects of centrality. 
 - strength: how many connections does the AU have
 - eigenvector: high if AU is connected with a lot of AUs that also have a lot of connections
 - betweenness: number of shortest connections that go through the AU; does it connect otherwise unconnected elements?
 - transitivity: how many triads is the element in (triad == all three elements are connected)
 - hub_score: similar to eigenvector
 - page_rank: calculates the influence an element has over all it's neighbours
 - modularity: if modularity is high, the element clearly clusters with other elements
 - community membership: elements that have the same membership cluster with each other
 - community.value: if this is above 0.3, then there are clearly distinct clusters in this dataset

While these centrality measures concern the elements within a network, we can also calculate information flow etc within across a network.

```{r}
kable(network.summary.graph(angry.net), align = 'c', row.names = F, digits = 3)
```


Here, we see that there are 22 elements, 28 connections between them, which means that 12.1% of all possible connections are filled. The graph is highly transitive (== if A and B are connected and A and C are connected, B and C are also connected), so the dyadic connections probably arise out of higher-order combinations. The diameter is the 'furthest' connection. The degree centralisation is the mean degree/strength of all elements. Mean distance is the mean number of 'steps' to get from one element to the next in the network.

Let's see what happens if we do this across the different emotions.

```{r}
xx = lapply(multi.net, function(x){
        network.summary.graph(x)})
xx=do.call(rbind, xx)
xx = cbind(emotion = names(multi.net), xx)
kable(xx, align = 'c', row.names = F, digits = 3)
```

We see that the density of the different emotion networks differs considerably, but they all have pretty low density (mainly because they all rely on a small set of AUs). Fear and Anger seem to involve more AUs than the others. Some (Anger, Surprise, Disgust) are pretty transitive (AUs all usually appear together), while some (Fear, Happy) are less transitive (indicating that they have different configurations). 


\newpage
# Additional functions

## Dimension reduction and clustering
I have added two functions now that show you how the events cluster; one is based on t-distributed stochastic neighbor embedding (tsne), which in this case is purely used for plotting, even though more can be done with the underlying function. Tsne is essentially a more advanced discriminant function analysis; it tries to cluster cases along two dimensions to maximize the distance between them. The function is very basic but makes nice graphs. You are hoping for a clear distinction based on your conditions. The function gives both the model and the ggplot.

```{r tsne, fig.width=6, fig.height=4, fig.align='center', message=F}
p = netfacs.tsne(netfacs.data = angry.face)
p$plot
```

The second function that is now included is based on UMAP (uniform manifold approximation and projection), which is similar to tsne but tries even harder to distinguish cases. For this function, I have included an unsupervised learning mechanism based on k-Means clustering: essentially, the UMAP function reduces the information of all elements to two dimensions; then a Gaussian mixture model identifies how many clusters are likely in the data; and then the kmeans function detects how these clusters are distributed. The function returns a plot with the assigned clusters, the clusters themselves, the UMAP object (which can be used to assign new cases, to test where they fit), and if we have known conditions, then it compares the observed with the expected clusters. This function can potentially built the basis to identify different signals without previous knowledge of how many distinct signals exist in the data.

```{r clusters, fig.width=6, fig.height=4, fig.align='center', message=F}
p = netfacs.clustering(netfacs.data = angry.face, condition = angry.face$used.data$condition)
p$plot
kable(p$comparison.table, align = 'c', row.names = F, digits = 3)
```

The results are always slightly different, but usually each emotion is pretty clearly defined by one cluster, or contempt and fear are mixed. So, we could take a dataset where we do not necessarily know what the underlying 'types' of signals are (e.g., a primate dataset of facial expressions) and see how well the algorithm tells apart 'open mouth faces', 'silent bared teeth faces' etc., similar to how we would do this with calls.

## Bayesian linear mixed models

Sometimes, you have more than one predictor variable. The networks and permutation/bootstrap analyses are nice when you want to compare conditions, but what if one of the predictors is continuous (e.g. distance between sender and receiver of the signal)? Sometimes you are interested in the impact of inter-individual differences on distributions. One option is to run a linear model with each element as a binary response variable, and your predictor variables as fixed and random effects. Doing this in a Bayesian framework is the most intuitive: the estimates of Bayesian models can be transformed into probabilities, and distribution plots for predictors give a good idea of the impact each variable has. They also make for great plots. I have added a function, 'element.bayesian', which lets the user define the predictors and then runs a Bayesian linear model for each of the elements that occurs more than 5% of the time as response. The function pops out nice ggplots for each fixed effect, but also contains the model object, so further results and plots can be extracted easily. Here, I only show the example of action units 1 and 12 to give an idea of what is possible with this function.

```{r bayesian, fig.width=6, fig.height=4, fig.align='center', message=F, cache=T}
bayesian.results = element.bayesian(netfacs.data = angry.face, test.elements = c('1', '12'), formula = '~emotion', predictors = list(emotion = au.info$emotion), warmup = 500, iter = 1000, autocorrelation = F)
bayesian.results$X1$emotion$plot
bayesian.results$X12$emotion$plot

```

For AU12, we see that it is strongly represented in Happy (probability around 1), a bit in Contempt (probability around 0.3), and not in the others.

## Entropy

There is surpising little work on the information contained in facial expressions, even though this would be a great way to measure complexity. One way to quantify the amount of information in a system is by looking at how informative each observed case is. The idea is that, if in a condition, all events are exactly the same, this condition is very easily predicted and adding cases will add little information. In contrast, if under the condition, all observed events are different, then each new case that I observed adds information about the condition. This is the underlying idea of entropy measures: Entropy is maximal in entirely random systems. Entropy is minimal in perfectly ordered systems. There is potentially an insane amount of information in FACS data: for example, 30 elements can be combined in around 8 billion different ways. We know this is not the case, so there is clearly order and rules in the system.

There are two ways of looking at entropy: one is to determine how much entropy there is in a system as a whole, compared to what we would predict if the system was entirely random. In an ordered system, few of the possible options should be selected, the difference between observed and random entropy should be large, telling us that it would be easy to predict what happens. In a complex system, lots of possible options are selected, the observed entropy approaches the random entropy, so predicting each new facial expression is harder. So, the first entropy measure gives the ratio between observed overall entropy and predicted overall entropy under random conditions.

```{r}
xx = lapply(multi.facs, function(x){
        entropy.overall(x)})
xx = cbind(emotion = names(multi.facs), entropy.ratio = round(unlist(xx), 3))
kable(xx, align = 'c', row.names = F, digits = 3)
```

Here, we see that the different emotions differ in terms of their entropy ratio (ratios close to 0 mean order, ratios close to 1 mean chaos). As we can see, happy and surprised faces, which are both made up of mainly one expression, are very predictable. Fear, on the other hand, where no two expressions are exactly the same, is highly chaotic. With increasing sample size, this would probably change, but the difference between contexts is still quite robust.

The second way of looking at entropy is to identify at which combination size combinatorial rules apply. We can do this by looking at the 'entropy slope', the change of entropy with increasing information. Here, the zero-order entropy is the maximum information content in a system with the number of elements but random distribution of elements. First-order entropy is the information content given the observed probabilities of each element in the system. If the drop in entropy from zero to first order is large, differences between elements in probability are large; if the drop is small, elements are quite equiprobable. The second-order entropy contains the information content in case one element is already known; if there is a large drop from the first to the second order is large, than there are a lot of rules restricting which elements are combined. The third-order entropy contains the information content in case two elements are already known: can there still be variation of the third element? By comparing how the different orders are connected in a condition, we can determine where rules exist and where variation exists.


```{r entropyslope, fig.width=6, fig.height=4, fig.align='center', message=F}
xx = lapply(multi.facs, function(x){
        entropy.slope(x, entropy.level = 6, random = F)})
aa = do.call(rbind,xx)
aa$emotion = sort(rep(names(xx), 7))

p = ggplot(data = aa, aes(x = order, y = entropy, color = emotion)) +
  geom_point(aes(color = emotion), cex = 3)
p

```

What we see here is that we basically have three types of conditions: in suprise and happiness, there is lower entropy (i.e. more rules) in the lower orders of entropy, and then entropy goes to almost random at higher levels. This indicates that there are a number of action units that are really predictive, but how these are combined is less certain (probably because there is a low number of overall combinations. This fits with our previous results on these emotions. For contempt, entropy crashes to almost zero by the third order, implying that once three elements are known, the fourth element is deterministic. The remaining four emotions (anger, sadness, fear, disgust) all follow a highly similar trajectory: with increasing numbers of elements, there is increasing order, so when three elements are known there are fewer possible outcomes than when two elements are known etc, but as large combinations exist, it is not deterministic. 

